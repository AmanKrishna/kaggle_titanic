{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9512e9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2138f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ad310",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1891af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "titanic = pd.read_csv('titanic passenger list.csv')\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ece0fa",
   "metadata": {},
   "source": [
    "## Functions: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714c0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing Age\n",
    "def update_age(params, age_df):\n",
    "    pclass = params[0]\n",
    "    title = params[1]\n",
    "    sex = params[2]\n",
    "    age = params[3]\n",
    "    if pd.isnull(age):\n",
    "        age = np.float(age_df[(age_df['title'] == title) & (age_df[\"Sex\"] == sex) & (age_df['Pclass'] == pclass)][\"Age\"])\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4490429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Remaining\n",
    "def handle_missing_value(all_data, train):\n",
    "    # Handle Cabin\n",
    "    all_data[\"Cabin\"] = train[\"Cabin\"].apply(lambda x: \"X\" if pd.isnull(x) or x == \"T\" else x)\n",
    "    \n",
    "    # Handle Embarked\n",
    "    all_data.loc[all_data['Embarked'].isnull(), 'Embarked'] = train[\"Embarked\"].mode()[0]\n",
    "    \n",
    "    # Fill Fare\n",
    "    all_data.loc[all_data['Fare'].isnull(), 'Fare'] = train['Fare'].median()\n",
    "    \n",
    "    # Family Ticket Size\n",
    "    add_family_ticket_size(all_data)\n",
    "    \n",
    "    # Fill missing ages using training data\n",
    "    age_df = all_data[0:891].groupby(['Pclass','title','Sex']).Age.median().reset_index()\n",
    "    all_data['Age'] = all_data[['Pclass', 'title', 'Sex', 'Age']].apply(lambda x: update_age(x, age_df), axis = 1)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94182cc7",
   "metadata": {},
   "source": [
    "## Functions: Add Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881be5f1",
   "metadata": {},
   "source": [
    "### Add Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eccae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_title(df):\n",
    "    # Grouping Title\n",
    "    new_title = {\n",
    "        'Mr' : 'Mr','Ms' : 'Ms','Mrs' : 'Mrs','Rev' : 'officer','Sir' : 'royalty','theCountess' : 'royalty','Dona' : 'royalty','Capt' : 'officer','Col' : 'officer','Don' : 'royalty','Dr' : 'officer','Jonkheer' : 'royalty','Lady' : 'royalty','Major' : 'officer','Master' : 'kid','Miss' : 'Ms','Mlle' : 'Ms','Mme' : 'Mrs'\n",
    "    }\n",
    "\n",
    "    #Add Title\n",
    "    df['title'] = df['Name'].apply(lambda x: x.split(\",\")[1])\n",
    "    df['title'] = df['title'].apply(lambda x: x.split(\".\")[0])\n",
    "    df.title = df.title.str.replace(' ', '')\n",
    "    # Group Title\n",
    "    df['title'] = df['title'].apply(lambda x: new_title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87268bf",
   "metadata": {},
   "source": [
    "### Add Cabin Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e0f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cabin_section(df):\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].apply(lambda x: \"X\" if pd.isnull(x) or x == \"T\" else x)\n",
    "    df[\"Cabin_Section\"] = df['Cabin'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda43bb",
   "metadata": {},
   "source": [
    "### Add Family Ticket Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d4dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_family_ticket_size(df):\n",
    "    df[\"Family_Size\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    df[\"Ticket_Group_Size\"] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    # Grouping Family Sizes\n",
    "    family_map = {\n",
    "        1: 'Alone', \n",
    "        2: 'Small', \n",
    "        3: 'Small', \n",
    "        4: 'Small', \n",
    "        5: 'Medium', \n",
    "        6: 'Medium', \n",
    "        7: 'Large', \n",
    "        8: 'Large', \n",
    "        11: 'Large'\n",
    "    }\n",
    "    all_data['Family_Size_Grouped'] = all_data['Family_Size'].map(family_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ecdc0",
   "metadata": {},
   "source": [
    "### Add Survival Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff2ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Survival Rates (Percentage) using Ticket, Cabin and Family Name\n",
    "def add_surival_rates(x, survival_rate_df, feature_name, new_feature):\n",
    "    feature_val = x[feature_name]\n",
    "    # For Test Data to see if same Ticket is present in Train data\n",
    "    # For Training Data update survival rate only if this ticket is present in Test Data\n",
    "    if feature_val in list(survival_rate_df[feature_name]):\n",
    "        x[new_feature] = np.float(survival_rate_df[survival_rate_df[feature_name] == feature_val]['Survived'])\n",
    "    return x\n",
    "\n",
    "def add_survival_rates(all_data):\n",
    "    # Split Data\n",
    "    x_train = all_data[0:891]\n",
    "    x_test = all_data[891:]\n",
    "    \n",
    "    # Get Mean Age by Ticket, Cabin and Family Name\n",
    "    ticket_survival_rate_df = pd.DataFrame(x_train.groupby(['Ticket'])[['Survived']].mean().reset_index())\n",
    "    cabin_survival_rate_df = pd.DataFrame(x_train.groupby(['Cabin'])['Survived'].mean().reset_index())\n",
    "    name_survival_rate_df = pd.DataFrame(x_train.groupby(['Family_Name'])['Survived'].mean().reset_index())\n",
    "    \n",
    "    # Get List of Ticket, Family name & Cabins in Test Data\n",
    "    test_ticket_list = list(x_test['Ticket'])\n",
    "    test_name_list = list(x_test['Family_Name'])\n",
    "    test_cabin_list = list(x_test['Cabin'])\n",
    "    \n",
    "    feature_name = ['Ticket', 'Cabin', 'Family_Name']\n",
    "    survival_feature_names = ['Ticket_Survival_Rate', 'Cabin_Survival_Rate', 'Name_Survival_Rate']\n",
    "    test_lists = [test_ticket_list, test_cabin_list, test_name_list]\n",
    "    grouped_dfs = [ticket_survival_rate_df, cabin_survival_rate_df, name_survival_rate_df]\n",
    "    \n",
    "    for i, j, k, l in zip(feature_name, survival_feature_names, test_lists, grouped_dfs):\n",
    "        x_test[[i, j]] = x_test[[i, j]].apply(lambda x: add_surival_rates(x, l, i, j), axis = 1)\n",
    "        # Update Survival Rate only if Ticket/Cabin/Family Name is present in test data\n",
    "        x_train[[i, j]] = x_train[[i,j]].apply(lambda x: add_surival_rates(x, l, i , j) if x[i] in k else x, axis = 1)\n",
    "    \n",
    "    all_data = pd.concat([x_train, x_test], sort=False)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf225a2",
   "metadata": {},
   "source": [
    "## Adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e0f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test\n",
    "all_data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Add Family Name\n",
    "all_data[\"Family_Name\"] = all_data['Name'].str.split(',', 1, expand=True)[0]\n",
    "\n",
    "# Bin Age and Fare\n",
    "# all_data[\"Fare_Bins\"] = pd.qcut(all_data[\"Fare\"], 15)\n",
    "# all_data[\"Age_Bins\"] = pd.qcut(all_data[\"Age\"], 11)\n",
    "\n",
    "add_family_ticket_size(all_data) \n",
    "add_new_title(all_data)\n",
    "add_cabin_section(all_data)\n",
    "\n",
    "# Add Mean Survival Rates\n",
    "all_data['Ticket_Survival_Rate'] = np.mean(train['Survived'])\n",
    "all_data['Cabin_Survival_Rate'] = np.mean(train['Survived'])\n",
    "all_data['Name_Survival_Rate'] = np.mean(train['Survived'])\n",
    "\n",
    "# Update Survival Rates\n",
    "all_data = add_survival_rates(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059e77c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_Name</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Ticket_Group_Size</th>\n",
       "      <th>Family_Size_Grouped</th>\n",
       "      <th>title</th>\n",
       "      <th>Cabin_Section</th>\n",
       "      <th>Ticket_Survival_Rate</th>\n",
       "      <th>Cabin_Survival_Rate</th>\n",
       "      <th>Name_Survival_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>Braund</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Small</td>\n",
       "      <td>Mr</td>\n",
       "      <td>X</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.299419</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Small</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Ms</td>\n",
       "      <td>X</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.299419</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Small</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Mr</td>\n",
       "      <td>X</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.299419</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare  ... Embarked Family_Name Family_Size  \\\n",
       "0      0         A/5 21171   7.2500  ...        S      Braund           2   \n",
       "1      0          PC 17599  71.2833  ...        C     Cumings           2   \n",
       "2      0  STON/O2. 3101282   7.9250  ...        S   Heikkinen           1   \n",
       "3      0            113803  53.1000  ...        S    Futrelle           2   \n",
       "4      0            373450   8.0500  ...        S       Allen           1   \n",
       "\n",
       "   Ticket_Group_Size  Family_Size_Grouped title Cabin_Section  \\\n",
       "0                  1                Small    Mr             X   \n",
       "1                  2                Small   Mrs             C   \n",
       "2                  1                Alone    Ms             X   \n",
       "3                  2                Small   Mrs             C   \n",
       "4                  1                Alone    Mr             X   \n",
       "\n",
       "  Ticket_Survival_Rate  Cabin_Survival_Rate  Name_Survival_Rate  \n",
       "0             0.383838             0.299419            0.383838  \n",
       "1             1.000000             1.000000            1.000000  \n",
       "2             0.383838             0.299419            0.383838  \n",
       "3             0.383838             0.383838            0.383838  \n",
       "4             0.383838             0.299419            0.383838  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f8af7",
   "metadata": {},
   "source": [
    "## Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0e031b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = handle_missing_value(all_data, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fc4a7",
   "metadata": {},
   "source": [
    "## Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ed4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(all_data):\n",
    "    all_data = all_data.drop(\n",
    "        [\n",
    "            'PassengerId', \n",
    "            'Survived',\n",
    "            'Name'\n",
    "        ], axis = 1)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10114a1",
   "metadata": {},
   "source": [
    "## Create Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1f16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummify_data(all_data):\n",
    "    # Columns that need to be dummified\n",
    "    dummy_cols = ['Sex','Pclass', 'Embarked', 'title', 'Cabin_Section', \n",
    "                  'Family_Size_Grouped', 'Cabin', 'Family_Name', 'Ticket']\n",
    "    \n",
    "    # Create Dummies\n",
    "    all_data = pd.get_dummies(all_data, prefix=dummy_cols, columns=dummy_cols)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41fb28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cols\n",
    "all_data = drop_cols(all_data)\n",
    "\n",
    "# Dummify Cols\n",
    "all_data = dummify_data(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e4dc1",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16e29c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (891, 1986)\n",
      "Test Shape: (418, 1986)\n"
     ]
    }
   ],
   "source": [
    "x_train = all_data[0:891]\n",
    "x_test = all_data[891:]\n",
    "y_train = train['Survived']\n",
    "print(\"Train Shape:\",x_train.shape)\n",
    "print(\"Test Shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925e3fb",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e41641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, x_train, x_test, y_train):\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    result = pd.concat(\n",
    "        [pd.DataFrame(test[\"PassengerId\"]),pd.DataFrame(predictions)], \n",
    "        ignore_index=True,\n",
    "        axis=1\n",
    "    )\n",
    "    headerList = ['PassengerId', 'Survived']\n",
    "    # converting data frame to csv\n",
    "    result.to_csv(\"submission.csv\", header=headerList, index=False)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033cf17f",
   "metadata": {},
   "source": [
    "## Get Cross Val Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce89d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x, y):\n",
    "    score=cross_val_score(model, x, y,scoring='accuracy', cv=5)\n",
    "    print(np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba3d47",
   "metadata": {},
   "source": [
    "## Fine Tuning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5be0f",
   "metadata": {},
   "source": [
    "#### Fine Tune max depth, max_samples, max_features & criterion used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "080d38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "{'criterion': 'gini', 'max_depth': 19, 'max_features': 'auto', 'max_samples': 0.5}\n",
      "0.8608248069801018\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    n_estimators=101,\n",
    ")\n",
    "params = [{\n",
    "    'max_depth' : np.arange(1,21,1),\n",
    "    'max_samples' : np.arange(0.1, 1.1, 0.1),\n",
    "    'max_features' : ['auto', 'log', 'sqrt'],\n",
    "    'criterion' : ['gini']\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5bd346",
   "metadata": {},
   "source": [
    "#### Fix: Criterion & max_feature \n",
    "#### Fine Tune: Max_depth and max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67c09d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 147 candidates, totalling 735 fits\n",
      "{'max_depth': 19, 'max_samples': 0.4900000000000001}\n",
      "0.8619546795555835\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    n_estimators=101,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    ")\n",
    "params = [{\n",
    "    'max_depth' : np.arange(18,25,1),\n",
    "    'max_samples' : np.arange(0.4, 0.61, 0.01),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb3a60",
   "metadata": {},
   "source": [
    "#### Fix: Max_Depth & Max_Samples \n",
    "#### Modify: min_samples_split & min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "06fb4552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 361 candidates, totalling 1805 fits\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "0.7856631724311093\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    n_estimators=101,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49\n",
    ")\n",
    "params = [{\n",
    "    'min_samples_split' : np.arange(2,21,1),\n",
    "    'min_samples_leaf' : np.arange(2,21,1)\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bb0a5c",
   "metadata": {},
   "source": [
    "#### Fix: min_samples_split & min_samples_leaf\n",
    "#### Modify: n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "9f985e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'n_estimators': 4511}\n",
      "0.7867804908668633\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 2\n",
    ")\n",
    "params = [{\n",
    "    'n_estimators' : np.arange(11,5001,500),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "bebc59c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76664365, 0.78455841, 0.7834097 , 0.77779173, 0.78003264,\n",
       "       0.78452075, 0.7845333 , 0.78340343, 0.78565062, 0.78678049])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487cf594",
   "metadata": {},
   "source": [
    "#### Fine Tune: n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "b46fae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'n_estimators': 4401}\n",
      "0.7890339589479631\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 2\n",
    ")\n",
    "params = [{\n",
    "    'n_estimators' : np.arange(4001,5001,100),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "c707e1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78901513, 0.78116879, 0.78227983, 0.7845333 , 0.78903396,\n",
       "       0.7890214 , 0.78901513, 0.78678677, 0.78227983, 0.78340343])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "af9499ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "{'n_estimators': 4351}\n",
      "0.7901450003138535\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 2\n",
    ")\n",
    "params = [{\n",
    "    'n_estimators' : np.arange(4301,4502,10),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "cf886439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7845333 , 0.78003892, 0.78229239, 0.7845333 , 0.78678049,\n",
       "       0.790145  , 0.7845333 , 0.78116251, 0.78003264, 0.78227983,\n",
       "       0.78340343, 0.78228611, 0.78564434, 0.78004519, 0.78340343,\n",
       "       0.7856569 , 0.78116879, 0.7834097 , 0.78227355, 0.78564434,\n",
       "       0.78339715])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "eafa9777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'n_estimators': 4343}\n",
      "0.7890214048082356\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'gini',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 2\n",
    ")\n",
    "params = [{\n",
    "    'n_estimators' : np.arange(4341,4361,1),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    verbose = 10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "4d4f99bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77666185, 0.78003892, 0.7890214 , 0.77890905, 0.7856569 ,\n",
       "       0.78115624, 0.7845333 , 0.78003264, 0.78452702, 0.7834097 ,\n",
       "       0.78227983, 0.78676794, 0.7845333 , 0.78452075, 0.78452702,\n",
       "       0.78452702, 0.77891532, 0.78677421, 0.78452702, 0.78116879])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe5c30",
   "metadata": {},
   "source": [
    "## My 2 Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "ca462549",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    n_estimators = 4343,\n",
    "    max_features = 'auto',\n",
    "    criterion = 'entropy',\n",
    "    max_depth = 19,\n",
    "    max_samples = 0.49,\n",
    "    min_samples_split = 6,\n",
    "    min_samples_leaf = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "c09ec7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=2179,\n",
    "    max_depth=19,\n",
    "    max_samples=0.55,\n",
    "    criterion='entropy',\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
